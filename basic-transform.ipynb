{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Mecabによる形態素解析\n",
    "hinshiリストで指定した品詞のみ抽出する\n",
    "\"\"\"\n",
    "\n",
    "import MeCab\n",
    "mecab = MeCab.Tagger ()\n",
    "mecab.parse('')\n",
    "\n",
    "#形態素解析(特定の品詞のみ)\n",
    "def keitaiso(text):\n",
    "    node = mecab.parseToNode(text)\n",
    "    word=[]\n",
    "    hinshi = [\"名詞\",\"動詞\",\"形容詞\"]\n",
    "    while node:\n",
    "        feats = node.feature.split(',')\n",
    "        if feats[0] in hinshi :\n",
    "            try:\n",
    "                word.append(node.surface)  #単語を取得\n",
    "            except:\n",
    "                print(\"err: \" + str(node.surface))\n",
    "        node = node.next  #次の単語に進める\n",
    "    \n",
    "    print(\"形態素解析(Mecab) : \" + str(word), end='\\n\\n')\n",
    "    \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "KAKASIによる漢字，ひらがな，カタカナ，alfabetの相互変換\n",
    "'J'漢字 'H'ひらがな　'K'カタカナ　'a'alfabet\n",
    "今回は全てひらがなに変換する\n",
    "\"\"\"\n",
    "\n",
    "def kakasi(text):\n",
    "    from pykakasi import kakasi\n",
    "    kakasi = kakasi()\n",
    "    kakasi.setMode('J', 'H')\n",
    "    kakasi.setMode('K', 'H')\n",
    "    kakasi.setMode('H', 'H')\n",
    "    conv = kakasi.getConverter()\n",
    "    kakasi_text=conv.do(text)\n",
    "\n",
    "    print(\"ひらがな変換(KAKASI) : \" + kakasi_text, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cabochaによって単語を原型に変換\n",
    "\"\"\"\n",
    "\n",
    "import CaboCha\n",
    "\n",
    "def get_word(tree, chunk):\n",
    "    surface = ''\n",
    "    for i in range(chunk.token_pos, chunk.token_pos + chunk.token_size):\n",
    "        token = tree.token(i)\n",
    "        features = token.feature.split(',')\n",
    "        if features[0] == '名詞':\n",
    "            surface += token.surface\n",
    "        elif features[0] == '形容詞':\n",
    "            surface += features[6]\n",
    "            break\n",
    "        elif features[0] == '動詞':\n",
    "            surface += features[6]\n",
    "            break\n",
    "    return surface\n",
    "\n",
    "def get_2_words(word):\n",
    "    cp = CaboCha.Parser('-f1')\n",
    "    tree = cp.parse(word)\n",
    "    token = tree.token(0)\n",
    "    chunk_dic = token.chunk\n",
    "    return get_word(tree, chunk_dic)\n",
    "\n",
    "def change_original(word):\n",
    "    \n",
    "    word2=get_2_words(word)\n",
    "    \n",
    "    if(word2!=word):\n",
    "        print(\"原型変換(Cabocha) : \" + word + \" -> \"+word2)\n",
    "        \n",
    "    return word2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cabochaによって係り受け解析を行う\n",
    "主語と述語の関係を示す\n",
    "\"\"\"\n",
    "\n",
    "def cabocha(line):\n",
    "    cp = CaboCha.Parser('-f1')\n",
    "    tree = cp.parse(line)\n",
    "    chunk_dic = {}\n",
    "    chunk_id = 0\n",
    "    for i in range(0, tree.size()):\n",
    "        token = tree.token(i)\n",
    "        if token.chunk:\n",
    "            chunk_dic[chunk_id] = token.chunk\n",
    "            chunk_id += 1\n",
    "\n",
    "    tuples = []\n",
    "    for chunk_id, chunk in chunk_dic.items():\n",
    "        if chunk.link > 0:\n",
    "            from_surface =  get_word(tree, chunk)\n",
    "            to_chunk = chunk_dic[chunk.link]\n",
    "            to_surface = get_word(tree, to_chunk)\n",
    "            tuples.append((from_surface, to_surface))\n",
    "    return tuples\n",
    "\n",
    "def kakariuke(text):\n",
    "    tuples = cabocha(text)\n",
    "    for t in tuples:\n",
    "        print(\"係り受け解析(Cabocha) : \" + t[0] + ' => ' + t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original : 自然言語処理は難しかった．\n",
      "\n",
      "形態素解析(Mecab) : ['自然', '言語', '処理', '難しかっ']\n",
      "\n",
      "ひらがな変換(KAKASI) : しぜんげんごしょりはむずかしかった．\n",
      "\n",
      "原型変換(Cabocha) : 難しかっ -> 難しい\n",
      "原型変換(Cabocha) : ['自然', '言語', '処理', '難しい']\n",
      "\n",
      "係り受け解析(Cabocha) : 自然言語処理 => 難しい\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    text = \"自然言語処理は難しかった．\"\n",
    "    print(\"Original : \" + text , end='\\n\\n')\n",
    "\n",
    "    #通常の文字列を入力して，単語に区切る+特定の品詞のみ抽出する\n",
    "    keitaiso_text = keitaiso(text)\n",
    "    \n",
    "    #かな漢字混じり文を入力して，すべてひらがなに変換する\n",
    "    kakasi(text)\n",
    "    \n",
    "    #形態素解析された文章を入力して，単語を原型に変換する\n",
    "    for i in range(len(keitaiso_text)):\n",
    "        keitaiso_text[i] = change_original(keitaiso_text[i])\n",
    "    print(\"原型変換(Cabocha) : \" + str(keitaiso_text), end='\\n\\n')\n",
    "    \n",
    "    #通常の文字列を入力して，主語と述語の関係を得る\n",
    "    kakariuke(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
